---
description: Cool openAI thing
---

# Dalle e 2

### Overview

{% embed url="https://www.assemblyai.com/blog/how-dall-e-2-actually-works/" %}
good article
{% endembed %}

#### Text

#### Text to Image representation

In this stage the goal is to translate semantics to visual representation. Instead of a predictive model that predicts what caption a given image has, it actually just learns how related a caption and image are. This is why it is called a contrastive model rather than predictive. Therefore, the model learns a more abstract relationship between semantics and visual representation, allowing it derive meaning from natural language which can be translated to visual information. More on this and how it actually is trained here:

{% content-ref url="clip.md" %}
[clip.md](clip.md)
{% endcontent-ref %}

#### Image generation

#### Training
